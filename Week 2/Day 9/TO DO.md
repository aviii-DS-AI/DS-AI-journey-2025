# âœ… Day 9: Comparing Models & Feature Insight ğŸ”

---

## ğŸ§  Concepts to Learn
- [ ] What is a **Decision Tree Classifier**?
- [ ] Key differences: Logistic Regression vs Decision Tree
- [ ] Understanding:
  - [ ] Overfitting vs Underfitting
  - [ ] Feature Importance

---

## âš’ï¸ Hands-On Tasks
- [ ] Load Titanic dataset again (or reuse cleaned version)
- [ ] Train a **Decision Tree Classifier**
  - [ ] Use same X_train / y_train split from Day 8
  - [ ] Tune `max_depth` and `criterion`
- [ ] Predict and evaluate:
  - [ ] `accuracy_score`
  - [ ] `confusion_matrix`
  - [ ] `classification_report`

---

## ğŸ“Š Compare Models
- [ ] Compare Logistic Regression vs Decision Tree:
  - Accuracy
  - Precision / Recall
  - Confusion Matrix results
- [ ] Write a few lines on: Which one do you trust more and why?

---

## ğŸŒ¿ Bonus: Interpretability
- [ ] Use `plot_tree()` to visualize the Decision Tree
- [ ] Use `.feature_importances_` to rank the features
- [ ] Try `Seaborn` to plot feature importance as a bar graph

---

## ğŸ“º Quick Boosters
- [ ] [Decision Trees Explained Simply](https://www.youtube.com/watch?v=7VeUPuFGJHk)
- [ ] [Feature Importance in Trees](https://www.youtube.com/watch?v=HcqpanDadyQ)

---

## ğŸ““ Reflection Prompts
- Which model felt more intuitive?
- Did your tree overfit? How could you fix it?
- Which features turned out to be most important?

---

## ğŸ’¾ Optional Stretch Goals
- [ ] Try `RandomForestClassifier`
- [ ] Create a markdown report comparing all 3 models
- [ ] Try saving a model with `joblib` (model deployment prep!)

---
