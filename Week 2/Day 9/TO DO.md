# ✅ Day 9: Comparing Models & Feature Insight 🔍

---

## 🧠 Concepts to Learn
- [ ] What is a **Decision Tree Classifier**?
- [ ] Key differences: Logistic Regression vs Decision Tree
- [ ] Understanding:
  - [ ] Overfitting vs Underfitting
  - [ ] Feature Importance

---

## ⚒️ Hands-On Tasks
- [ ] Load Titanic dataset again (or reuse cleaned version)
- [ ] Train a **Decision Tree Classifier**
  - [ ] Use same X_train / y_train split from Day 8
  - [ ] Tune `max_depth` and `criterion`
- [ ] Predict and evaluate:
  - [ ] `accuracy_score`
  - [ ] `confusion_matrix`
  - [ ] `classification_report`

---

## 📊 Compare Models
- [ ] Compare Logistic Regression vs Decision Tree:
  - Accuracy
  - Precision / Recall
  - Confusion Matrix results
- [ ] Write a few lines on: Which one do you trust more and why?

---

## 🌿 Bonus: Interpretability
- [ ] Use `plot_tree()` to visualize the Decision Tree
- [ ] Use `.feature_importances_` to rank the features
- [ ] Try `Seaborn` to plot feature importance as a bar graph

---

## 📺 Quick Boosters
- [ ] [Decision Trees Explained Simply](https://www.youtube.com/watch?v=7VeUPuFGJHk)
- [ ] [Feature Importance in Trees](https://www.youtube.com/watch?v=HcqpanDadyQ)

---

## 📓 Reflection Prompts
- Which model felt more intuitive?
- Did your tree overfit? How could you fix it?
- Which features turned out to be most important?

---

## 💾 Optional Stretch Goals
- [ ] Try `RandomForestClassifier`
- [ ] Create a markdown report comparing all 3 models
- [ ] Try saving a model with `joblib` (model deployment prep!)

---
