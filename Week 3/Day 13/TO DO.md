# ✅ Day 13 – Support Vector Machines & Decision Boundaries

---

## 📘 Concepts to Learn
- [ ] What is a **Support Vector Machine (SVM)?**
  - [ ] What are support vectors?
  - [ ] Concept of margins and hyperplanes
  - [ ] Linear vs Non-linear SVMs
- [ ] Kernel Trick – what it does, and why it matters

---

## ⚙️ Hands-On Practice
- [ ] Load Titanic dataset (or cleaned version)
- [ ] Preprocess as needed (scale features if using `SVC`)
- [ ] Train:
  - [ ] `SVC(kernel='linear')`
  - [ ] `SVC(kernel='rbf')`
- [ ] Evaluate using:
  - [ ] Accuracy
  - [ ] Confusion Matrix
  - [ ] Classification Report

---

## 🔍 Concept Application
- [ ] Visualize decision boundaries (on dummy 2D data)
- [ ] Use `make_blobs()` or `make_moons()` with `matplotlib` or `seaborn`
- [ ] Compare visually:
  - [ ] Linear SVM vs Non-linear SVM
  - [ ] Tight vs wide margins

---

## 📺 Quick Boosters
- [ ] [SVM Explained Intuitively](https://www.youtube.com/watch?v=efR1C6CvhmE)
- [ ] [Kernel Trick Explained Simply](https://www.youtube.com/watch?v=Toet3EiSFcM)

---

## 📓 Journal Prompts
- What’s your mental image of how SVM separates data?
- Why are margins important in classification?
- Which kernel worked best on Titanic? Why do you think so?

---

## 🌱 Bonus Challenges (Optional)
- [ ] Try `StandardScaler()` on your data before SVM
- [ ] Compare models using `cross_val_score()`
- [ ] Try `Polynomial kernel` and observe performance

---
